{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from arrival_networkx.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from arrival_networkx import Arrival, get_branch_instance\n",
    "import numpy as np\n",
    "import random as rm\n",
    "from typing import List\n",
    "from collections import deque\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_run_procedure(instance: Arrival, S_subset: List[int]):\n",
    "    s_curr =  instance.s_0\n",
    "    s_next = instance.s_1\n",
    "    \n",
    "    w = {s:1 for s in S_subset}\n",
    "    \n",
    "    t = {s:0 for s in instance.vertices}\n",
    "    t[0] = 1\n",
    "    for v in S_subset:\n",
    "        t[instance.s_0[v]] += np.ceil(w[v]/2)\n",
    "        t[instance.s_1[v]] += np.floor(w[v]/2)\n",
    "    # print(t)\n",
    "    \n",
    "    waiting_set = []\n",
    "    for v in instance.vertices:\n",
    "        if v not in S_subset and v not in [instance.target_node, instance.sink_node]:\n",
    "            waiting_set.append(v)\n",
    "            \n",
    "    while len(waiting_set)>0:\n",
    "        waiting_set_ = [ws for ws in waiting_set if t[ws]>0]\n",
    "        if not waiting_set_:\n",
    "            break\n",
    "        \n",
    "        choose = rm.choice(waiting_set_)\n",
    "        # print(choose,t)\n",
    "        tau = rm.randint(1,t[choose])\n",
    "        t[choose] -= tau\n",
    "        t[s_curr[choose]] += np.ceil(tau/2)\n",
    "        t[s_next[choose]] += np.floor(tau/2)\n",
    "        \n",
    "        if tau & 1 : \n",
    "            temp = s_curr[choose]\n",
    "            s_curr[choose] = s_next[choose]\n",
    "            s_next[choose] = temp\n",
    "            \n",
    "        # break\n",
    "    print(\"final t array \",t) \n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_into_layers(instance : Arrival):\n",
    "    \"\"\"\n",
    "    Decompose the graph into layers based on the distance of the vertices to the destination nodes.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: A NetworkX graph instance.\n",
    "    - target_node: The target node (d).\n",
    "    - sink_node: The sink node (d').\n",
    "    \n",
    "    Returns:\n",
    "    - layers: A dictionary where key is the layer index and value is a list of nodes in that layer.\n",
    "    - max_dist: The maximum distance (layer index) found.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the layers dictionary\n",
    "    layers = {}\n",
    "    # Distance dictionary with initial values set to None for each node\n",
    "    dist = {node: float('inf') for node in instance.graph.nodes()}\n",
    "    \n",
    "    # Define a BFS procedure to calculate distances to {target_node, sink_node}\n",
    "    queue = deque([(instance.target_node, 0), (instance.sink_node, 0)])\n",
    "    while queue:\n",
    "        current_node, current_dist = queue.popleft()\n",
    "        if dist[current_node] == float('inf'):\n",
    "            dist[current_node] = current_dist\n",
    "            if current_dist not in layers:\n",
    "                layers[current_dist] = [current_node]\n",
    "            else:\n",
    "                layers[current_dist].append(current_node)\n",
    "            for neighbor in instance.graph.predecessors(current_node):\n",
    "                if dist[neighbor] == float('inf'):\n",
    "                    queue.append((neighbor, current_dist + 1))\n",
    "    \n",
    "    # Calculate max_dist\n",
    "    max_dist = max(dist.values())\n",
    "    \n",
    "    return layers, max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phi_set(instance: Arrival, phi: float) :\n",
    "    layers, max_dist = decompose_into_layers(instance) \n",
    "    print(layers)\n",
    "    S = []\n",
    "    U = layers[0]\n",
    "    for i in range(1,len(layers)):\n",
    "        if len(layers[i]) < phi*len(U):\n",
    "            S += layers[i]\n",
    "            U = []\n",
    "        U += layers[i]\n",
    "    return S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subexponential(instance: Arrival, phi: float):\n",
    "    S = compute_phi_set(instance, phi)\n",
    "    print(\"S is \",S)\n",
    "    t = multi_run_procedure(instance, S)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_instance = get_branch_instance(100,0.5)\n",
    "subexponential(hard_instance, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarski",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
