{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from arrival_networkx.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from arrival_networkx import *\n",
    "import numpy as np\n",
    "import random as rm\n",
    "from typing import List\n",
    "from collections import deque\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_phi(number_of_nodes):\n",
    "    return np.sqrt(3) / np.sqrt(2*number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_run_procedure(instance: Arrival, S_subset: List[int],w : dict):\n",
    "       \n",
    "    t = {s:0 for s in instance.vertices}\n",
    "    \n",
    "    t[0] = 1     # t[o] ← 1 /* traversal of (Y, o) */\n",
    "    for v in S_subset:\n",
    "        t[instance.s_0[v]] += np.ceil(w[v]/2) # /* dwi/2e traversals of (vi, seven(vi)) */\n",
    "        t[instance.s_1[v]] += np.floor(w[v]/2) # /* bwi/2c traversals of (vi, sodd(vi)) */\n",
    "    \n",
    "\n",
    "    # Let scurr and snext be arrays indexed by the vertices of V \\ S\n",
    "    s_curr =  instance.s_0 \n",
    "    s_next = instance.s_1\n",
    "            \n",
    "            \n",
    "    waiting_set = []\n",
    "    for v in instance.vertices:\n",
    "        if v not in S_subset and v not in [instance.target_node, instance.sink_node]:\n",
    "            waiting_set.append(v)\n",
    "            \n",
    "    while len(waiting_set) > 0: ## maintain all the vertices not in S \n",
    "        waiting_set_ = [ws for ws in waiting_set if t[ws]>0]\n",
    "        if not waiting_set_:\n",
    "            break\n",
    "        \n",
    "        choose = rm.choice(waiting_set_)\n",
    "        tau = rm.randint(1,t[choose])\n",
    "        \n",
    "        t[choose] -= tau\n",
    "        t[s_curr[choose]] += np.ceil(tau/2)\n",
    "        t[s_next[choose]] += np.floor(tau/2)\n",
    "        \n",
    "        if tau & 1 : \n",
    "            temp = s_curr[choose]\n",
    "            s_curr[choose] = s_next[choose]\n",
    "            s_next[choose] = temp\n",
    "          \n",
    "    return t[instance.target_node], t[instance.sink_node], {v:t[v] for v in S_subset}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_into_layers(instance: Arrival):\n",
    "    graph = instance.graph    \n",
    "    # Initialize the layers dictionary\n",
    "    layers = {}\n",
    "    # Distance dictionary with initial values set to None for each node\n",
    "    dist = {node: float('inf') for node in graph.nodes()}\n",
    "    \n",
    "    # Define a BFS procedure to calculate distances to {target_node, sink_node}\n",
    "    queue = deque([(instance.target_node, 0), (instance.sink_node, 0)])\n",
    "    while queue:\n",
    "        current_node, current_dist = queue.popleft()\n",
    "        if dist[current_node] == float('inf'):\n",
    "            dist[current_node] = current_dist\n",
    "            if current_dist not in layers:\n",
    "                layers[current_dist] = [current_node]\n",
    "            else:\n",
    "                layers[current_dist].append(current_node)\n",
    "            for neighbor in graph.predecessors(current_node):\n",
    "                if dist[neighbor] == float('inf'):\n",
    "                    queue.append((neighbor, current_dist + 1))\n",
    "    \n",
    "    # Calculate max_dist\n",
    "    print(dist)\n",
    "    max_dist = max(dist.values())\n",
    "    \n",
    "    return layers, max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phi_set(instance: Arrival, phi: float) :\n",
    "    layers, max_dist = decompose_into_layers(instance) \n",
    "    print(max_dist)\n",
    "    S = []\n",
    "    U = layers[0]\n",
    "    for i in range(1,max_dist+1):\n",
    "        if len(layers[i]) < phi*len(U):\n",
    "            S += layers[i]\n",
    "            U = []\n",
    "        U += layers[i]\n",
    "    return S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_w(w,w_new):\n",
    "    for key in w:\n",
    "        if w[key] != w_new[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def subexponential(instance: Arrival, phi: float):\n",
    "    S = compute_phi_set(instance, phi)\n",
    "    w = {s:10 for s in S}\n",
    "    t_d,t_sink, w_new = multi_run_procedure(instance, S, w)\n",
    "    counter = 1\n",
    "    while not compare_w(w,w_new):\n",
    "        w = w_new\n",
    "        t_d, t_sink, w_new = multi_run_procedure(instance, S, w)\n",
    "        counter += 1\n",
    "        \n",
    "    print(\"t_d is \",t_d, \"t_sink is \",t_sink, \"w is \",w_new)\n",
    "        \n",
    "    return t_d, t_sink, w_new, counter\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarski",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
